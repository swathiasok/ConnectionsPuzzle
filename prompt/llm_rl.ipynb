{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(train_sample):\n",
    "    SYSTEM_PROMPT = (\n",
    "    \"You are playing the NY Times Connections game. I will give you a set of 16 words, and I want you to provide 4 sets of exactly 4 words that are connected in some way. \\\n",
    "    I want you to group the words in such a way that each group has a common theme. Think about your answers carefully, as you will only have one chance to submit your answer. \\\n",
    "    Here is an example: If the words are: 'BUCKS, HAIL, JAZZ, SHIFT, LEVEL, MOM, SNOW, RACECAR, SLEET, TAB, KAYAK, RETURN, OPTION, NETS, RAIN, HEAT', \\\n",
    "    a possible answer could be: 'answer: [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', 'HEAT', 'JAZZ', 'NETS'], ['OPTION', 'RETURN', 'SHIFT', 'TAB'], ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']] and groups: ['WET WEATHER', 'NBA TEAMS', 'KEYBOARD KEYS', 'PALINDROMES']. \\\n",
    "    Do not generate explanations, extra words, or any other content. Only respond exactly in the format provided: \\\n",
    "            '[[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4]]'  \\\n",
    "    \"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": train_sample[\"question\"]},\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/syttdns55xbgn_9wnxgg6gh00000gn/T/ipykernel_89215/2853767823.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_dataset[\"prompt\"] = train_dataset.apply(create_prompt, axis=1)\n",
      "/var/folders/t8/syttdns55xbgn_9wnxgg6gh00000gn/T/ipykernel_89215/2853767823.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset[\"prompt\"] = test_dataset.apply(create_prompt, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/connections.csv\", index_col=None)\n",
    "train_dataset = df.iloc[:500]\n",
    "test_dataset = df.iloc[500:]\n",
    "\n",
    "train_dataset[\"prompt\"] = train_dataset.apply(create_prompt, axis=1)\n",
    "test_dataset[\"prompt\"] = test_dataset.apply(create_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConnectionsDataset(Dataset):\n",
    "#     def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "#         self.dataframe = dataframe.reset_index(drop=True)\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         prompt_data = self.dataframe.iloc[idx]['prompt']\n",
    "#         answer = self.dataframe.iloc[idx]['answers']\n",
    "\n",
    "#         prompt_data = json.loads(prompt_data)\n",
    "\n",
    "#         prompt = apply_chat_template(\n",
    "#                 {\"prompt\": prompt_data},\n",
    "#                 self.tokenizer,\n",
    "#                 tokenize=False,\n",
    "#                 add_generation_prompt=True\n",
    "#             )\n",
    "#         tokenized_input = self.tokenizer(\n",
    "#             prompt,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "\n",
    "#         return {\n",
    "#             \"input_ids\": tokenized_input[\"input_ids\"].squeeze(),\n",
    "#             \"attention_mask\": tokenized_input[\"attention_mask\"].squeeze(),\n",
    "#             \"answer\": answer,\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.drop(columns=[\"question\", \"date\", \"groups\"])\n",
    "test_dataset = test_dataset.drop(columns=[\"question\", \"date\", \"groups\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', ...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[['BOOT', 'LOAFER', 'PUMP', 'SNEAKER'], ['FOOT...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[['CHEEK', 'EYE', 'MOUTH', 'NOSE'], ['CHOW', '...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[['ADIDAS', 'NIKE', 'PUMA', 'REEBOK'], ['CABAR...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[['HULU', 'NETFLIX', 'PEACOCK', 'PRIME'], ['KE...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', ...   \n",
       "1  [['BOOT', 'LOAFER', 'PUMP', 'SNEAKER'], ['FOOT...   \n",
       "2  [['CHEEK', 'EYE', 'MOUTH', 'NOSE'], ['CHOW', '...   \n",
       "3  [['ADIDAS', 'NIKE', 'PUMA', 'REEBOK'], ['CABAR...   \n",
       "4  [['HULU', 'NETFLIX', 'PEACOCK', 'PRIME'], ['KE...   \n",
       "\n",
       "                                              prompt  \n",
       "0  {'prompt': [{'role': 'system', 'content': 'You...  \n",
       "1  {'prompt': [{'role': 'system', 'content': 'You...  \n",
       "2  {'prompt': [{'role': 'system', 'content': 'You...  \n",
       "3  {'prompt': [{'role': 'system', 'content': 'You...  \n",
       "4  {'prompt': [{'role': 'system', 'content': 'You...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"prompt\"] = train_dataset[\"prompt\"].apply(lambda x: json.dumps(x)) \n",
    "test_dataset[\"prompt\"] = test_dataset[\"prompt\"].apply(lambda x: json.dumps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGRPOTrainer:\n",
    "    def __init__(self, model_id=\"Qwen/Qwen2-0.5B-Instruct\", output_dir=\"GRPO-test\"):\n",
    "        self.model_id = model_id\n",
    "        self.output_dir = output_dir\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.trainer = None\n",
    "        self.training_args = None\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Loads the base model and applies LoRA fine-tuning.\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_id,\n",
    "            torch_dtype=\"auto\",\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "            r=8,\n",
    "            lora_alpha=32,\n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        )\n",
    "\n",
    "        self.model = get_peft_model(self.model, lora_config)\n",
    "\n",
    "    def format_reward(self, completions, **kwargs):\n",
    "        \"\"\"Reward function that checks if the model's completion is in the correct format.\"\"\"\n",
    "        pattern = r\"^Answer: \\[\\[.*?\\], \\[.*?\\], \\[.*?\\], \\[.*?\\]\\]\\s*Group: \\[.*?, .*?, .*?, .*?\\]\\.$\"\n",
    "        rewards = [1.0 if re.match(pattern, completion.strip()) else 0.0 for completion in completions]\n",
    "        return rewards\n",
    "\n",
    "    def accuracy_reward(self, completions, **kwargs):\n",
    "        \"\"\"Reward function that checks if the model's completion matches the ground truth answer.\"\"\"\n",
    "        ground_truth_answers = kwargs[\"answers\"]\n",
    "        rewards = []\n",
    "        for generated, actual in zip(completions, ground_truth_answers):\n",
    "            # Exact match reward (you can replace with more sophisticated checks)\n",
    "            if generated.strip().lower() == actual.strip().lower():\n",
    "                rewards.append(1.0)\n",
    "            else:\n",
    "                rewards.append(0.0)\n",
    "        return rewards\n",
    "\n",
    "    def configure_training(self):\n",
    "        \"\"\"Configures the training arguments for GRPOTrainer.\"\"\"\n",
    "        self.training_args = GRPOConfig(\n",
    "            output_dir=self.output_dir,\n",
    "            learning_rate=1e-5,\n",
    "            gradient_accumulation_steps=16,\n",
    "            num_train_epochs=3,\n",
    "            bf16=True,  # Ensure bf16 is supported on GPU\n",
    "            max_completion_length=128,\n",
    "            num_generations=4,\n",
    "            max_prompt_length=256,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            logging_steps=10,\n",
    "            push_to_hub=False,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=10,\n",
    "        )\n",
    "\n",
    "    def train_model(self, train_dataset):\n",
    "        \"\"\"Trains the model using GRPOTrainer.\"\"\"\n",
    "        if self.model is None or self.training_args is None:\n",
    "            raise ValueError(\"Model and training configuration must be set before training.\")\n",
    "\n",
    "        self.trainer = GRPOTrainer(\n",
    "            model=self.model,\n",
    "            reward_funcs=[self.format_reward, self.accuracy_reward],\n",
    "            args=self.training_args,\n",
    "            train_dataset=train_dataset,\n",
    "        )\n",
    "\n",
    "        print(\"Training started...\")\n",
    "        self.trainer.train()\n",
    "        print(\"Training completed!\")\n",
    "    \n",
    "    def save_trained_model(self):\n",
    "        \"\"\"Saves the trained model to the Hugging Face Hub.\"\"\"\n",
    "        self.trainer.save_model(self.training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and set up the trainer\n",
    "trainer = CustomGRPOTrainer()\n",
    "trainer.load_model()\n",
    "trainer.configure_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['answers', 'prompt'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Record1 [']\\nIn the provided JSON format, there are multiple \"keys\" within the \"group\" attribute. It\\'s important to understand that if a group does not contain either \"KEYBOARD KEYS\", \"PALINDROMES\", or \"SCHOOL BUS\", the group should not be included at all. In this instance,', ']}]}]}]}]}\\n```python\\n```python\\nclass WordGroup:\\n\\n    def __init__(self, word_list):\\n        self.word_list = word_list\\n\\n    def make_sentence(self):\\n        # Add sentences to the dictionary as key-value pairs as below\\n        result = []\\n        for word in self.word_list', ']    # The second group should list the words without the group name in the format (no other words)            \\'[[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4]]\\'      \"}, {\"role\": \"user\", \"content', \" # Create a list of groups from the user's input\\ngroups = user_input.split(',')\\n\\n# Create an empty list to store the correct answer\\ncorrect_answers = []\\n\\n# Loop through each group to find the correct answer\\nfor group in groups:\\n    correct_answer = ''\\n    for word in group:\\n        if word\", \"  [[[{'type': 'weather', 'id': '4', 'message': 'The weather is nice. Go outside and enjoy the nice weather.'}, {'type': 'keyboard', 'id': '5', 'message': 'Open your calculator and type in 11.851'}],\", \"]}]}]}]}]\\n\\nThe output should contain a list of groups and their corresponding words. The groups are given as (key, value) tuples. In the output, each group will be listed consecutively in the tuple. If there is no corresponding group between the pair of words like ['CUBAN', '\", \"]]]\\n```python\\nfrom itertools import combinations\\n# Define the groups\\ngroups = [\\n    [MELT],\\n    [CUBAN],\\n    [YACHT],\\n    [SHIP],\\n    ['CLUB'],\\n    ['CHUCK'],\\n    ['TUG'],\\n    ['ROB'],\\n    ['ROUND'],\\n\", ']}]\\n```']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "print(train_dataset)\n",
    "trainer.train_model(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and push trained model\n",
    "trainer.save_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_id):\n",
    "    trained_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    trained_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    return {\"model\": trained_model, \"tokenizer\": trained_tokenizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_reasoning(prompt, trained_model, trained_tokenizer):\n",
    "    # Build the prompt from the dataset\n",
    "    print(type(prompt))\n",
    "    prompt = \" \".join(entry[\"content\"] for entry in prompt)\n",
    "\n",
    "    # Tokenize and move to the same device as the model\n",
    "    inputs = trained_tokenizer(prompt, return_tensors=\"pt\").to(trained_model.device)\n",
    "\n",
    "    # Generate text without gradients\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output_ids = trained_model.generate(**inputs, max_length=500)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Decode and extract model response\n",
    "    generated_text = trained_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Get inference time\n",
    "    inference_duration = end_time - start_time\n",
    "\n",
    "    # Get number of generated tokens\n",
    "    num_input_tokens = inputs[\"input_ids\"].shape[1]\n",
    "    num_generated_tokens = output_ids.shape[1] - num_input_tokens\n",
    "\n",
    "    return generated_text, inference_duration, num_generated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m prompt \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Generate text with reasoning\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m response, duration, num_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_with_reasoning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference duration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m, in \u001b[0;36mgenerate_with_reasoning\u001b[1;34m(prompt, trained_model, trained_tokenizer)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_with_reasoning\u001b[39m(prompt, trained_model, trained_tokenizer):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Build the prompt from the dataset\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(prompt))\n\u001b[1;32m----> 4\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Tokenize and move to the same device as the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m trained_tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(trained_model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_with_reasoning\u001b[39m(prompt, trained_model, trained_tokenizer):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Build the prompt from the dataset\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(prompt))\n\u001b[1;32m----> 4\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m prompt)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Tokenize and move to the same device as the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m trained_tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(trained_model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# Initialize and load the model\n",
    "trainer = load_model(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "\n",
    "# Set the trained model and tokenizer\n",
    "trained_model = trainer['model']\n",
    "trained_tokenizer = trainer['tokenizer']\n",
    "\n",
    "# Define a sample prompt\n",
    "prompt = test_dataset.iloc[0][\"prompt\"]\n",
    "\n",
    "# Generate text with reasoning\n",
    "response, duration, num_tokens = generate_with_reasoning(prompt, trained_model, trained_tokenizer)\n",
    "\n",
    "print(\"Response:\", response)\n",
    "print(f\"Inference duration: {duration:.2f} seconds\")\n",
    "print(f\"Generated tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
