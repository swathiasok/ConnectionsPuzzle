{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Files\\College\\PG USC\\Courses\\CSCI - 566 DL\\Project\\ConnectionsPuzzle\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from trl import GRPOConfig, GRPOTrainer, apply_chat_template\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from math_verify import LatexExtractionConfig, parse, verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(train_sample):\n",
    "    SYSTEM_PROMPT = (\n",
    "    \"You are playing the NY Times Connections game. I will give you a set of 16 words, and I want you to provide 4 sets of exactly 4 words that are connected in some way. \\\n",
    "    I want you to group the words in such a way that each group has a common theme. Think about your answers carefully, as you will only have one chance to submit your answer. \\\n",
    "    Here is an example: If the words are: 'BUCKS, HAIL, JAZZ, SHIFT, LEVEL, MOM, SNOW, RACECAR, SLEET, TAB, KAYAK, RETURN, OPTION, NETS, RAIN, HEAT', \\\n",
    "    a possible answer could be: 'answer: [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', 'HEAT', 'JAZZ', 'NETS'], ['OPTION', 'RETURN', 'SHIFT', 'TAB'], ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']] and groups: ['WET WEATHER', 'NBA TEAMS', 'KEYBOARD KEYS', 'PALINDROMES']. \\\n",
    "    Give your answer strictly in the format (no other words): \\\n",
    "            '[[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4]]'  \\\n",
    "    \"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": train_sample[\"question\"]},\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreyas Nagesh\\AppData\\Local\\Temp\\ipykernel_25516\\3066995324.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_dataset[\"prompt\"] = train_dataset.apply(create_prompt, axis=1)\n",
      "C:\\Users\\Shreyas Nagesh\\AppData\\Local\\Temp\\ipykernel_25516\\3066995324.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset[\"prompt\"] = test_dataset.apply(create_prompt, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/connections.csv\", index_col=None)\n",
    "train_dataset = df.iloc[:500]\n",
    "test_dataset = df.iloc[500:]\n",
    "\n",
    "train_dataset[\"prompt\"] = train_dataset.apply(create_prompt, axis=1)\n",
    "test_dataset[\"prompt\"] = test_dataset.apply(create_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConnectionsDataset(Dataset):\n",
    "#     def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "#         self.dataframe = dataframe.reset_index(drop=True)\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         prompt_data = self.dataframe.iloc[idx]['prompt']\n",
    "#         answer = self.dataframe.iloc[idx]['answers']\n",
    "\n",
    "#         prompt_data = json.loads(prompt_data)\n",
    "\n",
    "#         prompt = apply_chat_template(\n",
    "#                 {\"prompt\": prompt_data},\n",
    "#                 self.tokenizer,\n",
    "#                 tokenize=False,\n",
    "#                 add_generation_prompt=True\n",
    "#             )\n",
    "#         tokenized_input = self.tokenizer(\n",
    "#             prompt,\n",
    "#             padding=\"max_length\",\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "\n",
    "#         return {\n",
    "#             \"input_ids\": tokenized_input[\"input_ids\"].squeeze(),\n",
    "#             \"attention_mask\": tokenized_input[\"attention_mask\"].squeeze(),\n",
    "#             \"answer\": answer,\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.drop(columns=[\"question\", \"date\", \"groups\"])\n",
    "test_dataset = test_dataset.drop(columns=[\"question\", \"date\", \"groups\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "answers",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6202d05b-cb68-48a7-b6c0-6743adfb3e12",
       "rows": [
        [
         "0",
         "[['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', 'HEAT', 'JAZZ', 'NETS'], ['OPTION', 'RETURN', 'SHIFT', 'TAB'], ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']]",
         "{'prompt': [{'role': 'system', 'content': \"You are playing the NY Times Connections game. I will give you a set of 16 words, and I want you to provide 4 sets of exactly 4 words that are connected in some way.     I want you to group the words in such a way that each group has a common theme. Think about your answers carefully, as you will only have one chance to submit your answer.     Here is an example: If the words are: 'BUCKS, HAIL, JAZZ, SHIFT, LEVEL, MOM, SNOW, RACECAR, SLEET, TAB, KAYAK, RETURN, OPTION, NETS, RAIN, HEAT',     a possible answer could be: 'answer: [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', 'HEAT', 'JAZZ', 'NETS'], ['OPTION', 'RETURN', 'SHIFT', 'TAB'], ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']] and groups: ['WET WEATHER', 'NBA TEAMS', 'KEYBOARD KEYS', 'PALINDROMES'].     Give your answer strictly in the format (no other words):             '[[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4]]'      \"}, {'role': 'user', 'content': 'RETURN, LEVEL, JAZZ, BUCKS, SHIFT, OPTION, HEAT, MOM, SNOW, KAYAK, SLEET, TAB, RACECAR, RAIN, NETS, HAIL'}]}"
        ],
        [
         "1",
         "[['BOOT', 'LOAFER', 'PUMP', 'SNEAKER'], ['FOOT', 'LEAGUE', 'MILE', 'YARD'], ['ESSENCE', 'PEOPLE', 'TIME', 'US'], ['ARE', 'QUEUE', 'SEA', 'WHY']]",
         "{'prompt': [{'role': 'system', 'content': \"You are playing the NY Times Connections game. I will give you a set of 16 words, and I want you to provide 4 sets of exactly 4 words that are connected in some way.     I want you to group the words in such a way that each group has a common theme. Think about your answers carefully, as you will only have one chance to submit your answer.     Here is an example: If the words are: 'BUCKS, HAIL, JAZZ, SHIFT, LEVEL, MOM, SNOW, RACECAR, SLEET, TAB, KAYAK, RETURN, OPTION, NETS, RAIN, HEAT',     a possible answer could be: 'answer: [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', 'HEAT', 'JAZZ', 'NETS'], ['OPTION', 'RETURN', 'SHIFT', 'TAB'], ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']] and groups: ['WET WEATHER', 'NBA TEAMS', 'KEYBOARD KEYS', 'PALINDROMES'].     Give your answer strictly in the format (no other words):             '[[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4]]'      \"}, {'role': 'user', 'content': 'SNEAKER, MILE, US, ARE, LEAGUE, BOOT, PUMP, YARD, LOAFER, QUEUE, PEOPLE, FOOT, TIME, WHY, SEA, ESSENCE'}]}"
        ],
        [
         "2",
         "[['CHEEK', 'EYE', 'MOUTH', 'NOSE'], ['CHOW', 'GOBBLE', 'SCARF', 'WOLF'], ['LAB', 'PEKE', 'PIT', 'POM'], ['AMIGO', 'KING', 'STOOGE', 'TENOR']]",
         "{'prompt': [{'role': 'system', 'content': \"You are playing the NY Times Connections game. I will give you a set of 16 words, and I want you to provide 4 sets of exactly 4 words that are connected in some way.     I want you to group the words in such a way that each group has a common theme. Think about your answers carefully, as you will only have one chance to submit your answer.     Here is an example: If the words are: 'BUCKS, HAIL, JAZZ, SHIFT, LEVEL, MOM, SNOW, RACECAR, SLEET, TAB, KAYAK, RETURN, OPTION, NETS, RAIN, HEAT',     a possible answer could be: 'answer: [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', 'HEAT', 'JAZZ', 'NETS'], ['OPTION', 'RETURN', 'SHIFT', 'TAB'], ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']] and groups: ['WET WEATHER', 'NBA TEAMS', 'KEYBOARD KEYS', 'PALINDROMES'].     Give your answer strictly in the format (no other words):             '[[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4]]'      \"}, {'role': 'user', 'content': 'AMIGO, LAB, GOBBLE, PIT, KING, TENOR, CHEEK, PEKE, SCARF, STOOGE, MOUTH, EYE, POM, WOLF, CHOW, NOSE'}]}"
        ],
        [
         "3",
         "[['ADIDAS', 'NIKE', 'PUMA', 'REEBOK'], ['CABARET', 'CAROUSEL', 'CATS', 'CHICAGO'], ['DUST', 'MOP', 'SWEEP', 'VACUUM'], ['BAT', 'IRON', 'SPIDER', 'SUPER']]",
         "{'prompt': [{'role': 'system', 'content': \"You are playing the NY Times Connections game. I will give you a set of 16 words, and I want you to provide 4 sets of exactly 4 words that are connected in some way.     I want you to group the words in such a way that each group has a common theme. Think about your answers carefully, as you will only have one chance to submit your answer.     Here is an example: If the words are: 'BUCKS, HAIL, JAZZ, SHIFT, LEVEL, MOM, SNOW, RACECAR, SLEET, TAB, KAYAK, RETURN, OPTION, NETS, RAIN, HEAT',     a possible answer could be: 'answer: [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', 'HEAT', 'JAZZ', 'NETS'], ['OPTION', 'RETURN', 'SHIFT', 'TAB'], ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']] and groups: ['WET WEATHER', 'NBA TEAMS', 'KEYBOARD KEYS', 'PALINDROMES'].     Give your answer strictly in the format (no other words):             '[[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4]]'      \"}, {'role': 'user', 'content': 'CATS, SUPER, SWEEP, MOP, ADIDAS, BAT, VACUUM, CAROUSEL, CABARET, DUST, PUMA, CHICAGO, IRON, REEBOK, SPIDER, NIKE'}]}"
        ],
        [
         "4",
         "[['HULU', 'NETFLIX', 'PEACOCK', 'PRIME'], ['KETCHUP', 'MAYO', 'RELISH', 'TARTAR'], ['BLUE', 'DOWN', 'GLUM', 'LOW'], ['GREEN', 'MUSTARD', 'PLUM', 'SCARLET']]",
         "{'prompt': [{'role': 'system', 'content': \"You are playing the NY Times Connections game. I will give you a set of 16 words, and I want you to provide 4 sets of exactly 4 words that are connected in some way.     I want you to group the words in such a way that each group has a common theme. Think about your answers carefully, as you will only have one chance to submit your answer.     Here is an example: If the words are: 'BUCKS, HAIL, JAZZ, SHIFT, LEVEL, MOM, SNOW, RACECAR, SLEET, TAB, KAYAK, RETURN, OPTION, NETS, RAIN, HEAT',     a possible answer could be: 'answer: [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', 'HEAT', 'JAZZ', 'NETS'], ['OPTION', 'RETURN', 'SHIFT', 'TAB'], ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']] and groups: ['WET WEATHER', 'NBA TEAMS', 'KEYBOARD KEYS', 'PALINDROMES'].     Give your answer strictly in the format (no other words):             '[[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4]]'      \"}, {'role': 'user', 'content': 'TARTAR, GLUM, RELISH, SCARLET, MAYO, BLUE, PLUM, PRIME, GREEN, HULU, KETCHUP, PEACOCK, NETFLIX, DOWN, LOW, MUSTARD'}]}"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', ...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[['BOOT', 'LOAFER', 'PUMP', 'SNEAKER'], ['FOOT...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[['CHEEK', 'EYE', 'MOUTH', 'NOSE'], ['CHOW', '...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[['ADIDAS', 'NIKE', 'PUMA', 'REEBOK'], ['CABAR...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[['HULU', 'NETFLIX', 'PEACOCK', 'PRIME'], ['KE...</td>\n",
       "      <td>{'prompt': [{'role': 'system', 'content': 'You...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  [['HAIL', 'RAIN', 'SLEET', 'SNOW'], ['BUCKS', ...   \n",
       "1  [['BOOT', 'LOAFER', 'PUMP', 'SNEAKER'], ['FOOT...   \n",
       "2  [['CHEEK', 'EYE', 'MOUTH', 'NOSE'], ['CHOW', '...   \n",
       "3  [['ADIDAS', 'NIKE', 'PUMA', 'REEBOK'], ['CABAR...   \n",
       "4  [['HULU', 'NETFLIX', 'PEACOCK', 'PRIME'], ['KE...   \n",
       "\n",
       "                                              prompt  \n",
       "0  {'prompt': [{'role': 'system', 'content': 'You...  \n",
       "1  {'prompt': [{'role': 'system', 'content': 'You...  \n",
       "2  {'prompt': [{'role': 'system', 'content': 'You...  \n",
       "3  {'prompt': [{'role': 'system', 'content': 'You...  \n",
       "4  {'prompt': [{'role': 'system', 'content': 'You...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"prompt\"] = train_dataset[\"prompt\"].apply(lambda x: json.dumps(x)) \n",
    "test_dataset[\"prompt\"] = test_dataset[\"prompt\"].apply(lambda x: json.dumps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGRPOTrainer:\n",
    "    def __init__(self, model_id=\"Qwen/Qwen2-0.5B-Instruct\", output_dir=\"GRPO-test\"):\n",
    "        self.model_id = model_id\n",
    "        self.output_dir = output_dir\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.trainer = None\n",
    "        self.training_args = None\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Loads the base model and applies LoRA fine-tuning.\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_id,\n",
    "            torch_dtype=\"auto\",\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "            r=8,\n",
    "            lora_alpha=32,\n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        )\n",
    "\n",
    "        self.model = get_peft_model(self.model, lora_config)\n",
    "\n",
    "    def format_reward(self, completions, **kwargs):\n",
    "        print(\"Record1\", completions)\n",
    "        \"\"\"Reward function that checks if the model's completion is in the correct format.\"\"\"\n",
    "        pattern = r\"^Answer: \\[\\[.*?\\], \\[.*?\\], \\[.*?\\], \\[.*?\\]\\]\\s*Group: \\[.*?, .*?, .*?, .*?\\]\\.$\"\n",
    "        rewards = [1.0 if re.match(pattern, completion.strip()) else 0.0 for completion in completions]\n",
    "        return rewards\n",
    "\n",
    "    def accuracy_reward(self, completions, **kwargs):\n",
    "        \"\"\"Reward function that checks if the model's completion matches the ground truth answer.\"\"\"\n",
    "        ground_truth_answers = kwargs[\"answers\"]\n",
    "        rewards = []\n",
    "        for generated, actual in zip(completions, ground_truth_answers):\n",
    "            # Exact match reward (you can replace with more sophisticated checks)\n",
    "            if generated.strip().lower() == actual.strip().lower():\n",
    "                rewards.append(1.0)\n",
    "            else:\n",
    "                rewards.append(0.0)\n",
    "        return rewards\n",
    "\n",
    "    def configure_training(self):\n",
    "        \"\"\"Configures the training arguments for GRPOTrainer.\"\"\"\n",
    "        self.training_args = GRPOConfig(\n",
    "            output_dir=self.output_dir,\n",
    "            learning_rate=1e-5,\n",
    "            gradient_accumulation_steps=16,\n",
    "            num_train_epochs=1,\n",
    "            bf16=True,  # Ensure bf16 is supported on GPU\n",
    "            max_completion_length=64,\n",
    "            num_generations=4,\n",
    "            max_prompt_length=128,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            logging_steps=10,\n",
    "            push_to_hub=False,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=10,\n",
    "        )\n",
    "\n",
    "    def train_model(self, train_dataset):\n",
    "        \"\"\"Trains the model using GRPOTrainer.\"\"\"\n",
    "        if self.model is None or self.training_args is None:\n",
    "            raise ValueError(\"Model and training configuration must be set before training.\")\n",
    "\n",
    "        self.trainer = GRPOTrainer(\n",
    "            model=self.model,\n",
    "            reward_funcs=[self.format_reward, self.accuracy_reward],\n",
    "            args=self.training_args,\n",
    "            train_dataset=train_dataset,\n",
    "        )\n",
    "\n",
    "        print(\"Training started...\")\n",
    "        self.trainer.train()\n",
    "        print(\"Training completed!\")\n",
    "    \n",
    "    def save_trained_model(self):\n",
    "        \"\"\"Saves the trained model to the Hugging Face Hub.\"\"\"\n",
    "        self.trainer.save_model(self.training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and set up the trainer\n",
    "trainer = CustomGRPOTrainer()\n",
    "trainer.load_model()\n",
    "trainer.configure_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['answers', 'prompt'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Record1 ['  print(grouping_results(group))  [[\"[[4 words of group1], [1 words of group2]]\"], [\"[[4 words of group3], [1 words of group4]]\"], [\"[[4 words of group1], [4 words of group2], [4 words of group3], [4', ']}]}]}]}]}]}\\n```python\\ndef parse_input(input_data):\\n    \"\"\"\\n    Parses a string containing multiple groups (such as \\'KEYBOARD KEYS\\', \\'PALINDROMES\\') \\n    into a dictionary where each group is separated by a comma and each element is converted\\n    to lower case before being', \"]\\n\\nThis example uses Python's `collections` module to define the rules for each group and the `group1`, `group2`, `group3`, `group4`, 'HARDY', 'FURIOUS', 'PUFFIN', 'SUNFLOWER', 'BEACH', 'INCRASE\", ' What would be the output of the code? The output should be a list of strings, where each string represents a group and is formatted as \"[4 words of group1], [4 words of group2], [4 words of group3], [4 words of group4].\" In this case, the code would output', ' \"flot\" = [{\\'element\\': \\'<strong>FISHES</strong>\\', \\'id\\': \\'172\\', \\'type\\': \\'group3\\', \\'index\\': 0, \\'value\\': [\\'FLANK\\', \\'FLANK\\', \\'FLANK\\', \\'FLANK\\', \\'FLANK\\']}, {\\'element\\':', '], \"100%\"}. The query is:   \"Do those groupings mention the terms \\'chuck\\', \\'chuck\\', \\'chuck\\', \\'chuck\\', \\'sue\\'?\"  We get: \\n```python\\n{\\'text\\': \\'Do those groupings mention the terms \"chuck\",', \"]}\\n    res = client.execute_sql_query(sql_query)\\n    res = str(res[1:-1])   # Remove quotes and \\\\n and \\\\t\\n    df = pd.DataFrame(res.split('\\\\n'), columns=['col1', 'col2', 'col3', 'col4', 'col5', '\", ']}]}]}]}]}\\n``` python\\nimport re\\n\\nclass Weather:\\n    def __init__(self, weather):\\n        self.weather = re.split(\"\\\\s+\", weather)\\n    \\n    def get_weather(self):\\n        return \"\\\\n\".join(self.weather)    \\n\\nweather_forecast = Weather(\"MELT, CUBAN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Files\\College\\PG USC\\Courses\\CSCI - 566 DL\\Project\\ConnectionsPuzzle\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3662: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  ctx_manager = torch.cpu.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "print(train_dataset)\n",
    "trainer.train_model(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and push trained model\n",
    "trainer.save_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_id):\n",
    "    trained_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    trained_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    return {\"model\": trained_model, \"tokenizer\": trained_tokenizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_reasoning(prompt, trained_model, trained_tokenizer):\n",
    "    # Build the prompt from the dataset\n",
    "    print(type(prompt))\n",
    "    prompt = \" \".join(entry[\"content\"] for entry in prompt)\n",
    "\n",
    "    # Tokenize and move to the same device as the model\n",
    "    inputs = trained_tokenizer(prompt, return_tensors=\"pt\").to(trained_model.device)\n",
    "\n",
    "    # Generate text without gradients\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output_ids = trained_model.generate(**inputs, max_length=500)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Decode and extract model response\n",
    "    generated_text = trained_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Get inference time\n",
    "    inference_duration = end_time - start_time\n",
    "\n",
    "    # Get number of generated tokens\n",
    "    num_input_tokens = inputs[\"input_ids\"].shape[1]\n",
    "    num_generated_tokens = output_ids.shape[1] - num_input_tokens\n",
    "\n",
    "    return generated_text, inference_duration, num_generated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m prompt \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Generate text with reasoning\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m response, duration, num_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_with_reasoning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference duration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m, in \u001b[0;36mgenerate_with_reasoning\u001b[1;34m(prompt, trained_model, trained_tokenizer)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_with_reasoning\u001b[39m(prompt, trained_model, trained_tokenizer):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Build the prompt from the dataset\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(prompt))\n\u001b[1;32m----> 4\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Tokenize and move to the same device as the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m trained_tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(trained_model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_with_reasoning\u001b[39m(prompt, trained_model, trained_tokenizer):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Build the prompt from the dataset\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(prompt))\n\u001b[1;32m----> 4\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m prompt)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Tokenize and move to the same device as the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m trained_tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(trained_model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# Initialize and load the model\n",
    "trainer = load_model(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "\n",
    "# Set the trained model and tokenizer\n",
    "trained_model = trainer['model']\n",
    "trained_tokenizer = trainer['tokenizer']\n",
    "\n",
    "# Define a sample prompt\n",
    "prompt = test_dataset.iloc[0][\"prompt\"]\n",
    "\n",
    "# Generate text with reasoning\n",
    "response, duration, num_tokens = generate_with_reasoning(prompt, trained_model, trained_tokenizer)\n",
    "\n",
    "print(\"Response:\", response)\n",
    "print(f\"Inference duration: {duration:.2f} seconds\")\n",
    "print(f\"Generated tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
