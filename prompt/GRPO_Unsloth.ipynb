{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b83c516-4939-4755-8b5c-7dee8674f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb61c53-65b2-4182-8897-7afc71223593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.26.4 in /home1/vedanth/.local/lib/python3.12/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unsloth in /home1/vedanth/.local/lib/python3.12/site-packages (2025.3.19)\n",
      "Requirement already satisfied: vllm==0.7.2 in /home1/vedanth/.local/lib/python3.12/site-packages (0.7.2)\n",
      "Requirement already satisfied: psutil in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (7.0.0)\n",
      "Requirement already satisfied: sentencepiece in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (4.67.0)\n",
      "Requirement already satisfied: blake3 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.48.2 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (4.51.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.21.1)\n",
      "Requirement already satisfied: protobuf in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (3.20.3)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.115.12)\n",
      "Requirement already satisfied: aiohttp in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (3.11.16)\n",
      "Requirement already satisfied: openai>=1.52.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (1.71.0)\n",
      "Requirement already satisfied: uvicorn[standard] in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.34.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (2.11.2)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.21.1)\n",
      "Requirement already satisfied: pillow in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (11.0.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.9.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.10.11)\n",
      "Requirement already satisfied: outlines==0.1.11 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (1.2.2)\n",
      "Requirement already satisfied: xgrammar>=0.1.6 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.1.17)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (4.13.1)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (3.16.1)\n",
      "Requirement already satisfied: partial-json-parser in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (26.4.0)\n",
      "Requirement already satisfied: msgspec in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.19.0)\n",
      "Requirement already satisfied: gguf==0.10.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.10.0)\n",
      "Requirement already satisfied: importlib_metadata in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (8.6.1)\n",
      "Requirement already satisfied: mistral_common>=1.5.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.0->vllm==0.7.2) (1.5.4)\n",
      "Requirement already satisfied: pyyaml in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (6.0.2)\n",
      "Requirement already satisfied: six>=1.16.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (1.17.0)\n",
      "Requirement already satisfied: setuptools>=74.1.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (78.1.0)\n",
      "Requirement already satisfied: einops in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.9.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.9.1)\n",
      "Requirement already satisfied: depyf==0.18.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (3.1.1)\n",
      "Requirement already satisfied: ray>=2.9 in /home1/vedanth/.local/lib/python3.12/site-packages (from ray[default]>=2.9->vllm==0.7.2) (2.44.1)\n",
      "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (12.570.86)\n",
      "Requirement already satisfied: torch==2.5.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (2.5.1)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (2.5.1)\n",
      "Requirement already satisfied: torchvision==0.20.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.20.1)\n",
      "Requirement already satisfied: xformers==0.0.28.post3 in /home1/vedanth/.local/lib/python3.12/site-packages (from vllm==0.7.2) (0.0.28.post3)\n",
      "Requirement already satisfied: astor in /home1/vedanth/.local/lib/python3.12/site-packages (from depyf==0.18.0->vllm==0.7.2) (0.8.1)\n",
      "Requirement already satisfied: dill in /home1/vedanth/.local/lib/python3.12/site-packages (from depyf==0.18.0->vllm==0.7.2) (0.3.8)\n",
      "Requirement already satisfied: interegular in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (5.6.3)\n",
      "Requirement already satisfied: referencing in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (4.23.0)\n",
      "Requirement already satisfied: pycountry in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (20250224)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /home1/vedanth/.local/lib/python3.12/site-packages (from outlines==0.1.11->vllm==0.7.2) (0.1.26)\n",
      "Requirement already satisfied: networkx in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from torch==2.5.1->vllm==0.7.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1->vllm==0.7.2) (1.3.0)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.3.17 in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (2025.3.17)\n",
      "Requirement already satisfied: bitsandbytes in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (0.45.5)\n",
      "Requirement already satisfied: packaging in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (24.2)\n",
      "Requirement already satisfied: tyro in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (0.9.18)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (3.5.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (1.6.0)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (0.15.1)\n",
      "Requirement already satisfied: huggingface_hub in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (0.30.1)\n",
      "Requirement already satisfied: hf_transfer in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth) (0.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home1/vedanth/.local/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (19.0.1)\n",
      "Requirement already satisfied: pandas in /home1/vedanth/.local/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home1/vedanth/.local/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home1/vedanth/.local/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm==0.7.2) (0.46.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.0->vllm==0.7.2) (4.11.0.86)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from openai>=1.52.0->vllm==0.7.2) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from openai>=1.52.0->vllm==0.7.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from openai>=1.52.0->vllm==0.7.2) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from openai>=1.52.0->vllm==0.7.2) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /home1/vedanth/.local/lib/python3.12/site-packages (from openai>=1.52.0->vllm==0.7.2) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from pydantic>=2.9->vllm==0.7.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from pydantic>=2.9->vllm==0.7.2) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from pydantic>=2.9->vllm==0.7.2) (0.4.0)\n",
      "Requirement already satisfied: click>=7.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm==0.7.2) (8.1.8)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm==0.7.2) (1.1.0)\n",
      "Requirement already satisfied: aiosignal in /home1/vedanth/.local/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm==0.7.2) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in /home1/vedanth/.local/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm==0.7.2) (1.5.0)\n",
      "Requirement already satisfied: aiohttp_cors in /home1/vedanth/.local/lib/python3.12/site-packages (from ray[default]>=2.9->vllm==0.7.2) (0.8.1)\n",
      "Requirement already satisfied: colorful in /home1/vedanth/.local/lib/python3.12/site-packages (from ray[default]>=2.9->vllm==0.7.2) (0.5.6)\n",
      "Requirement already satisfied: py-spy>=0.4.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from ray[default]>=2.9->vllm==0.7.2) (0.4.0)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from ray[default]>=2.9->vllm==0.7.2) (1.71.0)\n",
      "Requirement already satisfied: opencensus in /home1/vedanth/.local/lib/python3.12/site-packages (from ray[default]>=2.9->vllm==0.7.2) (0.11.4)\n",
      "Requirement already satisfied: smart_open in /home1/vedanth/.local/lib/python3.12/site-packages (from ray[default]>=2.9->vllm==0.7.2) (7.1.0)\n",
      "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /home1/vedanth/.local/lib/python3.12/site-packages (from ray[default]>=2.9->vllm==0.7.2) (20.30.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from aiohttp->vllm==0.7.2) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from aiohttp->vllm==0.7.2) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home1/vedanth/.local/lib/python3.12/site-packages (from aiohttp->vllm==0.7.2) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from aiohttp->vllm==0.7.2) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from aiohttp->vllm==0.7.2) (1.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home1/vedanth/.local/lib/python3.12/site-packages (from requests>=2.26.0->vllm==0.7.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home1/vedanth/.local/lib/python3.12/site-packages (from requests>=2.26.0->vllm==0.7.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from requests>=2.26.0->vllm==0.7.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home1/vedanth/.local/lib/python3.12/site-packages (from requests>=2.26.0->vllm==0.7.2) (2025.1.31)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home1/vedanth/.local/lib/python3.12/site-packages (from tiktoken>=0.6.0->vllm==0.7.2) (2024.11.6)\n",
      "Requirement already satisfied: rich in /home1/vedanth/.local/lib/python3.12/site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /home1/vedanth/.local/lib/python3.12/site-packages (from unsloth_zoo>=2025.3.17->unsloth) (25.1.1)\n",
      "Requirement already satisfied: ninja in /home1/vedanth/.local/lib/python3.12/site-packages (from xgrammar>=0.1.6->vllm==0.7.2) (1.11.1.4)\n",
      "Requirement already satisfied: nanobind>=2.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from xgrammar>=0.1.6->vllm==0.7.2) (2.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /home1/vedanth/.local/lib/python3.12/site-packages (from importlib_metadata->vllm==0.7.2) (3.21.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home1/vedanth/.local/lib/python3.12/site-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home1/vedanth/.local/lib/python3.12/site-packages (from tyro->unsloth) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from tyro->unsloth) (4.4.2)\n",
      "Requirement already satisfied: h11>=0.8 in /home1/vedanth/.local/lib/python3.12/site-packages (from uvicorn[standard]->vllm==0.7.2) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home1/vedanth/.local/lib/python3.12/site-packages (from uvicorn[standard]->vllm==0.7.2) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home1/vedanth/.local/lib/python3.12/site-packages (from uvicorn[standard]->vllm==0.7.2) (1.1.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from uvicorn[standard]->vllm==0.7.2) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home1/vedanth/.local/lib/python3.12/site-packages (from uvicorn[standard]->vllm==0.7.2) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home1/vedanth/.local/lib/python3.12/site-packages (from uvicorn[standard]->vllm==0.7.2) (15.0.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home1/vedanth/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm==0.7.2) (1.0.7)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home1/vedanth/.local/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm==0.7.2) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm==0.7.2) (0.24.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /home1/vedanth/.local/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm==0.7.2) (0.3.9)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm==0.7.2) (4.3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from jinja2->outlines==0.1.11->vllm==0.7.2) (3.0.2)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /home1/vedanth/.local/lib/python3.12/site-packages (from opencensus->ray[default]>=2.9->vllm==0.7.2) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from opencensus->ray[default]>=2.9->vllm==0.7.2) (2.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home1/vedanth/.local/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home1/vedanth/.local/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
      "Requirement already satisfied: wrapt in /home1/vedanth/.local/lib/python3.12/site-packages (from smart_open->ray[default]>=2.9->vllm==0.7.2) (1.17.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home1/vedanth/.local/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.7.2) (1.69.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /home1/vedanth/.local/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.7.2) (1.26.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.7.2) (2.38.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.7.2) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.7.2) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home1/vedanth/.local/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.7.2) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm==0.7.2) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home1/vedanth/.local/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from ipywidgets) (9.1.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home1/vedanth/.local/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /home1/vedanth/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home1/vedanth/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home1/vedanth/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home1/vedanth/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home1/vedanth/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home1/vedanth/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home1/vedanth/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home1/vedanth/.local/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home1/vedanth/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home1/vedanth/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home1/vedanth/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home1/vedanth/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install numpy==1.26.4\n",
    "!{sys.executable} -m pip install unsloth vllm==0.7.2\n",
    "!{sys.executable} -m pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72475ee0-fb8f-4b8b-9dd2-b470033ee240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import torch\n",
    "import re\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5f6133-efb3-43a7-95ed-bc13e0436e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 04-07 22:31:58 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb8cb197-4ea9-4f3c-8a30-d78b41e63d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = '''\n",
    "You are playing the NY Times Connections game. Your task is to categorize 16 given words into exactly 4 groups of 4 words each, based on shared common themes.\n",
    "\n",
    "Solve the puzzle using these clear steps:\n",
    "\n",
    "1. THINK STEP-BY-STEP: Begin by carefully analyzing the words within <thinking> tags. Identify their meanings, relationships, and possible groupings logically.\n",
    "Example:\n",
    "<thinking>To solve this, I will first look for obvious groupings like NBA teams, palindrome words, weather-related words, or computer keys. Then, I'll group these words accordingly and ensure each word belongs to exactly one group.</thinking>\n",
    "\n",
    "2. SHOW YOUR REASONING: After identifying each grouping, briefly explain why these words belong together. Clearly indicate the context or theme.\n",
    "\n",
    "3. PROVIDE FINAL ANSWER: After clearly grouping and justifying all four sets, provide ONLY your final solution within <answer> tags. Format your solution exactly as shown below.\n",
    "\n",
    "Example:\n",
    "<answer>\n",
    "[['HAIL', 'RAIN', 'SLEET', 'SNOW'],\n",
    " ['BUCKS', 'HEAT', 'JAZZ', 'NETS'],\n",
    " ['OPTION', 'RETURN', 'SHIFT', 'TAB'],\n",
    " ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']]\n",
    "</answer>\n",
    "\n",
    "Important Notes:\n",
    "- Categories should be specific\n",
    "- Words cannot appear in more than one group.\n",
    "- Categories can include compound words, shared prefixes/suffixes, pop culture references, or common phrases.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "USER: [BUCKS, HAIL, JAZZ, SHIFT, LEVEL, MOM, SNOW, RACECAR, SLEET, TAB, KAYAK, RETURN, OPTION, NETS, RAIN, HEAT]\n",
    "\n",
    "SOLUTION:\n",
    "[['HAIL', 'RAIN', 'SLEET', 'SNOW'],\n",
    " ['BUCKS', 'HEAT', 'JAZZ', 'NETS'],\n",
    " ['OPTION', 'RETURN', 'SHIFT', 'TAB'],\n",
    " ['KAYAK', 'LEVEL', 'MOM', 'RACECAR']]\n",
    "\n",
    "Explanation:\n",
    "- WEATHER TERMS: 'HAIL', 'RAIN', 'SLEET', 'SNOW'\n",
    "- NBA TEAMS: 'BUCKS', 'HEAT', 'JAZZ', 'NETS'\n",
    "- KEYBOARD KEYS: 'OPTION', 'RETURN', 'SHIFT', 'TAB'\n",
    "- PALINDROMES: 'KAYAK', 'LEVEL', 'MOM', 'RACECAR'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df57a8aa-f048-4e70-9335-631d7fa23887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106e1d79151345cfb2bc9c0a336308e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_connections_questions(split = \"train\"):\n",
    "    data = load_dataset('csv', data_files='dataset/final_transformed_connections.csv')[split]\n",
    "    data = data.train_test_split(test_size=0.1, seed=3407)\n",
    "    train_data = data['train']\n",
    "    test_data = data['test']\n",
    "    train_data = train_data.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'assistant', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': x['questions']}\n",
    "        ],\n",
    "        'answer': (x['answer'])\n",
    "    })\n",
    "    return train_data, test_data # type: ignore\n",
    "\n",
    "dataset, test_dataset = get_connections_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fccaee-fdcc-4890-92f0-8b0878c38dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thinking_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function for including thinking tags\"\"\"\n",
    "    rewards = []\n",
    "    for completion in completions:\n",
    "        try:\n",
    "            reward = 0.0\n",
    "            # Extract all thinking blocks\n",
    "            for message in completion:\n",
    "                if message[\"role\"] == \"assistant\" and message.get(\"content\"):\n",
    "                    content = message[\"content\"]\n",
    "\n",
    "                    # Count opening and closing tags\n",
    "                    opening_tags = len(re.findall(r\"<thinking>\", content))\n",
    "                    closing_tags = len(re.findall(r\"</thinking>\", content))\n",
    "\n",
    "                    if opening_tags == 0 or closing_tags == 0:\n",
    "                        continue\n",
    "\n",
    "                    if opening_tags == closing_tags:\n",
    "                        reward += 0.5\n",
    "                    else:\n",
    "                        reward += 0.1\n",
    "            reward = min(reward, 1.5)\n",
    "            rewards.append(reward)\n",
    "        except Exception as e:\n",
    "            print(f\"{RED}Error in thinking_reward_func: {e}{RESET}\")\n",
    "            rewards.append(0.0)\n",
    "    assert len(rewards) == len(completions)\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def answer_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function for including answer tags\"\"\"\n",
    "    rewards = []\n",
    "    for completion in completions:\n",
    "        try:\n",
    "            reward = 0.0\n",
    "            # Extract all answer blocks\n",
    "            for message in completion:\n",
    "                if message[\"role\"] == \"assistant\" and message.get(\"content\"):\n",
    "                    content = message[\"content\"]\n",
    "\n",
    "                    # Count opening and closing tags\n",
    "                    opening_tags = len(re.findall(r\"<answer>\", content))\n",
    "                    closing_tags = len(re.findall(r\"</answer>\", content))\n",
    "\n",
    "                    if opening_tags == 0 or closing_tags == 0:\n",
    "                        continue\n",
    "\n",
    "                    if opening_tags == 1 and closing_tags == 1:\n",
    "                        reward += 0.5\n",
    "                    else:\n",
    "                        reward += 0.1\n",
    "            reward = min(reward, 1.5)\n",
    "            rewards.append(reward)\n",
    "        except Exception as e:\n",
    "            print(f\"{RED}Error in thinking_reward_func: {e}{RESET}\")\n",
    "            rewards.append(0.0)\n",
    "    assert len(rewards) == len(completions)\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function tailored for NY Times Connections game puzzle answers\"\"\"\n",
    "    rewards = []\n",
    "    for completion, expected_answer in zip(completions, answer):\n",
    "        try:\n",
    "            reward = 0.0\n",
    "\n",
    "            # Extract the answer from completion\n",
    "            predicted_answer = None\n",
    "            for message in completion:\n",
    "                if message[\"role\"] == \"assistant\":\n",
    "                    content = message.get(\"content\", \"\")\n",
    "                    matches = re.findall(r\"<answer>(.*?)</answer>\", content, re.DOTALL)\n",
    "                    if matches:\n",
    "                        predicted_answer = matches[-1].strip()\n",
    "\n",
    "            if predicted_answer is None:\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Convert string representations of lists into actual Python lists for comparison\n",
    "            try:\n",
    "                predicted_groups = eval(predicted_answer)\n",
    "                expected_groups = eval(expected_answer)\n",
    "\n",
    "                if isinstance(predicted_groups, list) and isinstance(expected_groups, list):\n",
    "                    if predicted_groups == expected_groups:\n",
    "                        reward += 5.0\n",
    "                    else:\n",
    "                        # Check partial matches (correct groups)\n",
    "                        correct_groups = sum(1 for group in predicted_groups if group in expected_groups)\n",
    "                        reward += correct_groups * 1.25  # Partial credit per correct group\n",
    "                else:\n",
    "                    reward = 0.0\n",
    "\n",
    "            except Exception:\n",
    "                reward = 0.0\n",
    "\n",
    "            rewards.append(reward)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in correctness_reward_func: {e}\")\n",
    "            rewards.append(0.0)\n",
    "\n",
    "    assert len(rewards) == len(completions)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "621fd05f-1cc1-4f87-a3e7-d9da41fd1e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.51.0. vLLM: 0.7.2.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.451 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit with actual GPU utilization = 49.66%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.6 with VRAM = 44.45 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 288.\n",
      "Unsloth: vLLM's KV Cache can use up to 20.86 GB. Also swap space = 6 GB.\n",
      "INFO 04-07 22:33:06 config.py:542] This model supports multiple tasks: {'classify', 'embed', 'reward', 'generate', 'score'}. Defaulting to 'generate'.\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.0.self_attn', 'model.layers.1.mlp', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.7.mlp', 'model.layers.24.mlp', 'model.layers.26.mlp', 'model.layers.15.self_attn'], 'llm_int8_threshold': 6.0}\n",
      "INFO 04-07 22:33:06 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":288}, use_cached_outputs=False, \n",
      "INFO 04-07 22:33:07 cuda.py:230] Using Flash Attention backend.\n",
      "INFO 04-07 22:33:07 model_runner.py:1110] Starting to load model unsloth/qwen2.5-1.5b-instruct-unsloth-bnb-4bit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W407 22:33:07.662663999 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 22:33:08 loader.py:1102] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
      "INFO 04-07 22:33:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277556039324455ab251a11b4c3514e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddee7d029ce945f8812692ec9d25165d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 22:33:42 model_runner.py:1115] Loading model weights took 1.4331 GB\n",
      "INFO 04-07 22:33:42 punica_selector.py:18] Using PunicaWrapperGPU.\n",
      "INFO 04-07 22:33:46 worker.py:267] Memory profiling takes 4.17 seconds\n",
      "INFO 04-07 22:33:46 worker.py:267] the current vLLM instance can use total_gpu_memory (44.45GiB) x gpu_memory_utilization (0.50) = 22.08GiB\n",
      "INFO 04-07 22:33:46 worker.py:267] model weights take 1.43GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 1.57GiB; the rest of the memory reserved for KV Cache is 19.02GiB.\n",
      "INFO 04-07 22:33:46 executor_base.py:110] # CUDA blocks: 44509, # CPU blocks: 14043\n",
      "INFO 04-07 22:33:46 executor_base.py:115] Maximum concurrency for 1024 tokens per request: 695.45x\n",
      "INFO 04-07 22:33:50 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 39/39 [00:26<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 22:34:17 model_runner.py:1562] Graph capturing finished in 27 secs, took 0.67 GiB\n",
      "INFO 04-07 22:34:17 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 35.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 1024 # Can increase for longer reasoning traces\n",
    "lora_rank = 8 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.5, # Reduce if out of memory\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = lora_rank,\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80f4f0a-aa75-4583-9a50-b45bcc9361b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 4\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    use_vllm = True, # use vLLM for fast inference!\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 16, # Increase to 4 for smoother training\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = 128,\n",
    "    max_completion_length = 64,\n",
    "    num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    save_steps = 10,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe225784-737e-47a9-ba4a-42c43d0b836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 580 | Num Epochs = 1 | Total steps = 36\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 16 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 9,232,384/5,000,000,000 (0.18% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 14:27, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completion_length</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / thinking_reward_func</th>\n",
       "      <th>rewards / correctness_reward_func</th>\n",
       "      <th>rewards / answer_format_reward_func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>63.296875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>63.328125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>63.671875</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>63.921875</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>63.812500</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.033667</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>63.968750</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>63.968750</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.033667</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>63.531250</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.098584</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>62.578125</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>63.953125</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>63.968750</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>63.515625</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>63.937500</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>62.437500</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>63.671875</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.036084</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=4.649792238827407e-05, metrics={'train_runtime': 911.0325, 'train_samples_per_second': 0.637, 'train_steps_per_second': 0.04, 'total_flos': 0.0, 'train_loss': 4.649792238827407e-05})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        thinking_reward_func,\n",
    "        correctness_reward_func,\n",
    "        answer_format_reward_func,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b977e1ee-376b-4286-b881-152f06049928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_lora(\"grpo_saved_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c17230-211b-48ed-9cf8-0f5a46cfb3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 701.44 toks/s, output: 116.10 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<thinking>To solve this, I will first look for obvious groupings like animals, objects, related words, or common themes.</thinking>\\n\\n<answer>\\n[['BITE', 'YIELD', 'STOP', 'BEAK'],\\n ['HUSKY', 'DALMATIAN', 'WAVE', 'POODLE'],\\n ['BOXER', 'WAVE', 'BEAK'],\\n ['YIELD', 'ASLEEP', 'BITE', 'STOP']]\\n</answer>\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
    "    {\"role\" : \"user\", \"content\" : \"[BOXER, SLOW, MUZZLE, DALMATIAN, HUSKY, WAVE, SNOUT, DETOUR, TRUNK, YIELD, ASLEEP, BARRIER, POODLE, BEAK, STOP, BITE]\"},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    top_p = 0.95,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    text,\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
    ")[0].outputs[0].text\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d40d76e-081d-4d5e-86fb-21c85ffa7a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': 'BOXER, SLOW, MUZZLE, DALMATIAN, HUSKY, WAVE, SNOUT, DETOUR, TRUNK, YIELD, ASLEEP, BARRIER, POODLE, BEAK, STOP, BITE',\n",
       " 'answer': \"[['BOXER', 'DALMATIAN', 'HUSKY', 'POODLE'], ['BEAK', 'MUZZLE', 'SNOUT', 'TRUNK'], ['DETOUR', 'SLOW', 'STOP', 'YIELD'], ['ASLEEP', 'BARRIER', 'BITE', 'WAVE']]\",\n",
       " 'grouped_answers': \"DOG BREEDS - ['BOXER', 'DALMATIAN', 'HUSKY', 'POODLE']\\nANIMAL NOSES - ['BEAK', 'MUZZLE', 'SNOUT', 'TRUNK']\\nTRAFFIC SIGNS - ['DETOUR', 'SLOW', 'STOP', 'YIELD']\\nSOUND ___ - ['ASLEEP', 'BARRIER', 'BITE', 'WAVE']\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vedskernel",
   "language": "python",
   "name": "vedskernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
